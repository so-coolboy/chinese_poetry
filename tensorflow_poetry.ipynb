{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_poetry.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nC0NDzzbaDC",
        "outputId": "b4c71328-b7f6-405f-972f-8f809705bd1f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jan 28 10:00:04 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYQSO2wtVuHM"
      },
      "source": [
        "# Tensorflow实现自动写诗"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh_pRAbKstMP"
      },
      "source": [
        "### 模型采用的数据格式是：寒随穷律变，春逐鸟声开。初风飘带柳，晚雪间花梅。。。，采用的训练策略是，x是取六个字符，比如：寒随穷律变，对应的y就是下一个字符：春，下一对x和y就是随穷律变，春和逐，这样以此类推，y的可能性就是词表的大小，这里大概是5500+。实质就是采用softmax做多分类"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIH1Cb5iV3Kd"
      },
      "source": [
        "# 引入需要的工具库\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import os\r\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\r\n",
        "from tensorflow.keras import Input, Model\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.callbacks import LambdaCallback,ModelCheckpoint"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIB5rLOzaiLJ"
      },
      "source": [
        "!mkdir -p out"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V55_ZbFTWPxs",
        "outputId": "5dcbe5e9-154e-4fa3-dc00-dd6174bfb781"
      },
      "source": [
        "# 查看一下数据前面几行的内容\r\n",
        "!head -5 poetry.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "首春:寒随穷律变，春逐鸟声开。初风飘带柳，晚雪间花梅。碧林青旧竹，绿沼翠新苔。芝田初雁去，绮树巧莺来。\n",
            "初晴落景:晚霞聊自怡，初晴弥可喜。日晃百花色，风动千林翠。池鱼跃不同，园鸟声还异。寄言博通者，知予物外志。\n",
            "初夏:一朝春夏改，隔夜鸟花迁。阴阳深浅叶，晓夕重轻烟。哢莺犹响殿，横丝正网天。珮高兰影接，绶细草纹连。碧鳞惊棹侧，玄燕舞檐前。何必汾阳处，始复有山泉。\n",
            "度秋:夏律昨留灰，秋箭今移晷。峨嵋岫初出，洞庭波渐起。桂白发幽岩，菊黄开灞涘。运流方可叹，含毫属微理。\n",
            "仪鸾殿早秋:寒惊蓟门叶，秋发小山枝。松阴背日转，竹影避风移。提壶菊花岸，高兴芙蓉池。欲知凉气早，巢空燕不窥。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZx8fXrdXv88"
      },
      "source": [
        "# 定义配置类\r\n",
        "class ModelConfig(object):\r\n",
        "    poetry_file = 'poetry.txt'\r\n",
        "    weight_file = 'model/poetry_model.h5'\r\n",
        "    max_len = 6\r\n",
        "    batch_size = 32\r\n",
        "    learning_rate = 0.003\r\n",
        "\r\n",
        "# 定义文件读取函数\r\n",
        "def preprocess_data(ModelConfig):\r\n",
        "    # 首先将所有的诗取出来组成一个字符串\r\n",
        "    files_content = ''\r\n",
        "    with open(ModelConfig.poetry_file, 'r',encoding='UTF-8') as f:\r\n",
        "        for line in f:\r\n",
        "            # #每一行是一首诗，取出之后最后加上]号，表示结尾。\r\n",
        "            x = line.strip() + \"]\"    \r\n",
        "            # 取出具体诗的内容\r\n",
        "            x = x.split(\":\")[1]\r\n",
        "            # 根据长度过滤脏数据，如果诗的长度小于5，那么不采用，直接跳过这行\r\n",
        "            if len(x) <= 5 :\r\n",
        "                continue\r\n",
        "            # 过滤出五言绝句，通过判断第6个字符是不是逗号\r\n",
        "            if x[5] == '，':\r\n",
        "                #所有的字符串连接在一起\r\n",
        "                files_content += x\r\n",
        "            \r\n",
        "    # 字频统计,字符串外用list函数，会把它转化成一个列表，列表按字分割，每个字的类别还是字符串\r\n",
        "    words = sorted(list(files_content))\r\n",
        "    counted_words = {}\r\n",
        "    for word in words:\r\n",
        "        if word in counted_words:\r\n",
        "            counted_words[word] += 1\r\n",
        "        else:\r\n",
        "            counted_words[word] = 1\r\n",
        "\r\n",
        "    # 低频字过滤，如果出现次数小于等于2，就把这个字删除\r\n",
        "    delete_words = []\r\n",
        "    for key in counted_words:\r\n",
        "        if counted_words[key] <= 2:\r\n",
        "            delete_words.append(key)\r\n",
        "    for key in delete_words:\r\n",
        "        del counted_words[key]\r\n",
        "    # 返回可遍历的(键, 值) 元组数组。并且按照出现次数从大到小排列\r\n",
        "    wordPairs = sorted(counted_words.items(), key=lambda x: -x[1])\r\n",
        "    # 取出所有的字\r\n",
        "    words, _ = zip(*wordPairs)\r\n",
        "    words += (\" \",)\r\n",
        "    \r\n",
        "    # 构建 字到id的映射字典 与 id到字的映射字典\r\n",
        "    word2idx = dict((c, i) for i, c in enumerate(words))\r\n",
        "    idx2word = dict((i, c) for i, c in enumerate(words))\r\n",
        "    word2idx_dic = lambda x: word2idx.get(x, len(words) - 1)  #这是一个函数，可以传一个字符串参数，如果指定的值不存在，返回最后一个也就是空字符串对应的数字\r\n",
        "    return word2idx_dic, idx2word, words, files_content"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaF_uKrpZ4yi"
      },
      "source": [
        "class LSTMPoetryModel(object):\r\n",
        "    def __init__(self, config):\r\n",
        "        self.model = None\r\n",
        "        self.do_train = True\r\n",
        "        self.loaded_model = True\r\n",
        "        self.config = config\r\n",
        "\r\n",
        "        # 诗歌训练文件预处理\r\n",
        "        self.word2idx_dic, self.idx2word, self.words, self.files_content = preprocess_data(self.config)\r\n",
        "        \r\n",
        "        # 诗列表\r\n",
        "        self.poems = self.files_content.split(']')\r\n",
        "        # 诗的总数量\r\n",
        "        self.poems_num = len(self.poems)\r\n",
        "        \r\n",
        "        # 如果有预训练好的模型文件，则直接加载模型，否则开始训练\r\n",
        "        if os.path.exists(self.config.weight_file) and self.loaded_model:\r\n",
        "            self.model = load_model(self.config.weight_file)\r\n",
        "        else:\r\n",
        "            self.train()\r\n",
        "\r\n",
        "    def build_model(self):\r\n",
        "        '''LSTM模型构建'''\r\n",
        "        print('模型构建中...')\r\n",
        "\r\n",
        "        # 输入的维度\r\n",
        "        input_tensor = Input(shape=(self.config.max_len, len(self.words))) #输入是one-hot形式，这里是max_len*len(self.words)的矩阵，当作是嵌入好的，后面直接接LSTM\r\n",
        "        lstm = LSTM(512, return_sequences=True)(input_tensor)\r\n",
        "        dropout = Dropout(0.6)(lstm)\r\n",
        "        lstm = LSTM(256)(dropout)\r\n",
        "        dropout = Dropout(0.6)(lstm)\r\n",
        "        dense = Dense(len(self.words), activation='softmax')(dropout)\r\n",
        "        self.model = Model(inputs=input_tensor, outputs=dense)\r\n",
        "        optimizer = Adam(lr=self.config.learning_rate)\r\n",
        "        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\r\n",
        "\r\n",
        "    def sample(self, preds, temperature=1.0):\r\n",
        "        '''\r\n",
        "        temperature可以控制生成诗的创作自由约束度\r\n",
        "        当temperature<1.0时，模型会做一些随机探索，输出相对比较新的内容\r\n",
        "        当temperature>1.0时，模型预估方式偏保守\r\n",
        "        在训练的过程中可以看到temperature不同，结果也不同\r\n",
        "        就是一个概率分布变换的问题，保守的时候概率大的值变得更大，选择的可能性也更大\r\n",
        "        '''\r\n",
        "        preds = np.asarray(preds).astype('float64')\r\n",
        "        exp_preds = np.power(preds,1./temperature)\r\n",
        "        preds = exp_preds / np.sum(exp_preds)\r\n",
        "        prob = np.random.choice(range(len(preds)),1,p=preds)\r\n",
        "        return int(prob.squeeze())\r\n",
        "    \r\n",
        "    def generate_sample_result(self, epoch, logs):\r\n",
        "        '''训练过程中，每5个epoch打印出当前的学习情况'''\r\n",
        "        if epoch % 5 != 0:\r\n",
        "            return\r\n",
        "        \r\n",
        "        # 追加模式添加内容\r\n",
        "        with open('out/out.txt', 'a',encoding='utf-8') as f:\r\n",
        "            f.write('==================第{}轮=====================\\n'.format(epoch))\r\n",
        "                \r\n",
        "        print(\"\\n==================第{}轮=====================\".format(epoch))\r\n",
        "        for diversity in [0.7, 1.0, 1.3]:\r\n",
        "            print(\"------------设定诗词创作自由度约束参数为{}--------------\".format(diversity))\r\n",
        "            generate = self.predict_random(temperature=diversity)\r\n",
        "            print(generate)\r\n",
        "            \r\n",
        "            # 训练时的预测结果写入txt\r\n",
        "            with open('out/out.txt', 'a',encoding='utf-8') as f:\r\n",
        "                f.write(generate+'\\n')\r\n",
        "    \r\n",
        "    def predict_random(self,temperature = 1):\r\n",
        "        '''预估模式1：随机从库中选取一句开头的诗句，生成五言绝句'''\r\n",
        "        if not self.model:\r\n",
        "            print('没有预训练模型可用于加载！')\r\n",
        "            return\r\n",
        "        \r\n",
        "        index = random.randint(0, self.poems_num)\r\n",
        "        sentence = self.poems[index][: self.config.max_len]\r\n",
        "        generate = self.predict_sen(sentence,temperature=temperature)\r\n",
        "        return generate\r\n",
        "    \r\n",
        "    def predict_first(self, char,temperature =1):\r\n",
        "        '''预估模式2：根据给出的首个字，生成五言绝句'''\r\n",
        "        if not self.model:\r\n",
        "            print('没有预训练模型可用于加载！')\r\n",
        "            return\r\n",
        "        \r\n",
        "        index = random.randint(0, self.poems_num)\r\n",
        "        # 选取随机一首诗的最后max_len个字+给出的首个文字作为初始输入\r\n",
        "        sentence = self.poems[index][1-self.config.max_len:] + char\r\n",
        "        generate = str(char)\r\n",
        "        # 预测后面23个字\r\n",
        "        generate += self._preds(sentence,length=23,temperature=temperature)\r\n",
        "        return generate\r\n",
        "    \r\n",
        "    def predict_sen(self, text,temperature =1):\r\n",
        "        '''预估模式3：根据给出的前max_len个字，生成诗句'''\r\n",
        "        '''此例中，即根据给出的第一句诗句（含逗号），来生成古诗'''\r\n",
        "        if not self.model:\r\n",
        "            return\r\n",
        "        max_len = self.config.max_len\r\n",
        "        if len(text)<max_len:\r\n",
        "            print('给出的初始字数不低于 ',max_len)\r\n",
        "            return\r\n",
        "\r\n",
        "        sentence = text[-max_len:]\r\n",
        "        print('第一行为:',sentence)\r\n",
        "        generate = str(sentence)\r\n",
        "        generate += self._preds(sentence,length = 24-max_len,temperature=temperature)\r\n",
        "        return generate\r\n",
        "    \r\n",
        "    def predict_hide(self, text,temperature = 1):\r\n",
        "        '''预估模式4：根据给4个字，生成藏头诗五言绝句'''\r\n",
        "        if not self.model:\r\n",
        "            print('没有预训练模型可用于加载！')\r\n",
        "            return\r\n",
        "        if len(text)!=4:\r\n",
        "            print('藏头诗的输入必须是4个字！')\r\n",
        "            return\r\n",
        "        \r\n",
        "        index = random.randint(0, self.poems_num)\r\n",
        "        # 选取随机一首诗的最后max_len个字+给出的首个文字作为初始输入\r\n",
        "        sentence = self.poems[index][1-self.config.max_len:] + text[0]\r\n",
        "        generate = str(text[0])\r\n",
        "        print('第一行为 ',sentence)\r\n",
        "        \r\n",
        "        for i in range(5):\r\n",
        "            next_char = self._pred(sentence,temperature)           \r\n",
        "            sentence = sentence[1:] + next_char\r\n",
        "            generate+= next_char\r\n",
        "        \r\n",
        "        for i in range(3):\r\n",
        "            generate += text[i+1]\r\n",
        "            sentence = sentence[1:] + text[i+1]\r\n",
        "            for i in range(5):\r\n",
        "                next_char = self._pred(sentence,temperature)           \r\n",
        "                sentence = sentence[1:] + next_char\r\n",
        "                generate+= next_char\r\n",
        "\r\n",
        "        return generate\r\n",
        "    \r\n",
        "    \r\n",
        "    def _preds(self,sentence,length = 23,temperature =1):\r\n",
        "        '''\r\n",
        "        供类内部调用的预估函数，输入max_len长度字符串，返回length长度的预测值字符串\r\n",
        "        sentence:预测输入值\r\n",
        "        lenth:预测出的字符串长度\r\n",
        "        '''\r\n",
        "        sentence = sentence[:self.config.max_len]\r\n",
        "        generate = ''\r\n",
        "        for i in range(length):\r\n",
        "            pred = self._pred(sentence,temperature)\r\n",
        "            generate += pred\r\n",
        "            sentence = sentence[1:]+pred\r\n",
        "        return generate\r\n",
        "        \r\n",
        "        \r\n",
        "    def _pred(self,sentence,temperature =1):\r\n",
        "        '''供类内部调用的预估函数，根据一串输入，返回单个预测字符'''\r\n",
        "        if len(sentence) < self.config.max_len:\r\n",
        "            print('in def _pred,length error ')\r\n",
        "            return\r\n",
        "        \r\n",
        "        sentence = sentence[-self.config.max_len:]\r\n",
        "        x_pred = np.zeros((1, self.config.max_len, len(self.words)))\r\n",
        "        for t, char in enumerate(sentence):\r\n",
        "            x_pred[0, t, self.word2idx_dic(char)] = 1.\r\n",
        "        preds = self.model.predict(x_pred, verbose=0)[0]\r\n",
        "        next_index = self.sample(preds,temperature=temperature)\r\n",
        "        next_char = self.idx2word[next_index]\r\n",
        "        \r\n",
        "        return next_char\r\n",
        "\r\n",
        "    def data_generator(self):\r\n",
        "        '''生成器生成数据'''\r\n",
        "        # 注意这个生成器一次只生成一对x和y，而不是batch_size对，所以后面训练设置的参数也有改变。\r\n",
        "        i = 0\r\n",
        "        while 1:\r\n",
        "            x = self.files_content[i: i + self.config.max_len]\r\n",
        "            y = self.files_content[i + self.config.max_len]\r\n",
        "\r\n",
        "            if ']' in x or ']' in y:\r\n",
        "                i += 1\r\n",
        "                continue\r\n",
        "\r\n",
        "            y_vec = np.zeros(\r\n",
        "                shape=(1, len(self.words)),\r\n",
        "                dtype=np.bool\r\n",
        "            )\r\n",
        "            y_vec[0, self.word2idx_dic(y)] = 1.0\r\n",
        "\r\n",
        "            x_vec = np.zeros(\r\n",
        "                shape=(1, self.config.max_len, len(self.words)),\r\n",
        "                dtype=np.bool\r\n",
        "            )\r\n",
        "\r\n",
        "            for t, char in enumerate(x):\r\n",
        "                x_vec[0, t, self.word2idx_dic(char)] = 1.0\r\n",
        "\r\n",
        "            yield x_vec, y_vec\r\n",
        "            i += 1\r\n",
        "\r\n",
        "    def train(self):\r\n",
        "        '''训练模型'''\r\n",
        "        print('开始训练...')\r\n",
        "        number_of_epoch = len(self.files_content)-(self.config.max_len + 1)*self.poems_num\r\n",
        "        number_of_epoch /= self.config.batch_size \r\n",
        "        number_of_epoch = int(number_of_epoch / 1.5)\r\n",
        "        print('总迭代轮次为 ',number_of_epoch)\r\n",
        "        print('总诗词数量为 ',self.poems_num)\r\n",
        "        print('文件内容的长度为 ',len(self.files_content))\r\n",
        "\r\n",
        "        if not self.model:\r\n",
        "            self.build_model()\r\n",
        "\r\n",
        "        self.model.fit_generator(  \r\n",
        "            generator=self.data_generator(),\r\n",
        "            verbose=True,\r\n",
        "            steps_per_epoch=self.config.batch_size, #当生成器返回steps_per_epoch次数据时计一个epoch结束，执行下一个epoch，这里传入batch_size,也就是每训练32个数据，就认为训练完了一步。\r\n",
        "            epochs=10000,  #number_of_epoch\r\n",
        "            callbacks=[\r\n",
        "                ModelCheckpoint(self.config.weight_file, save_weights_only=False),\r\n",
        "                LambdaCallback(on_epoch_end=self.generate_sample_result)\r\n",
        "            ]\r\n",
        "        )"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OTXJuv4gaOsy",
        "outputId": "d565a312-afb6-4cbd-d395-3c5bd703da01"
      },
      "source": [
        "model = LSTMPoetryModel(ModelConfig)\r\n",
        "\r\n",
        "print('预训练模型加载成功！')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "==================第1890轮=====================\n",
            "------------设定诗词创作自由度约束参数为0.7--------------\n",
            "第一行为: 却上南山路，\n",
            "却上南山路，千新对，谁。新恨然。归，妾知柳，锦。\n",
            "------------设定诗词创作自由度约束参数为1.0--------------\n",
            "第一行为: 河水昏复晨，\n",
            "河水昏复晨，须飞金君入。怀见惟年太，玉傥关渡清。\n",
            "------------设定诗词创作自由度约束参数为1.3--------------\n",
            "第一行为: 北虏胶堪折，\n",
            "北虏胶堪折，玉处飞丈应。国拂垂太白，相万不军委。\n",
            "Epoch 1892/10000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 7.3896 - accuracy: 0.2339\n",
            "Epoch 1893/10000\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 6.7127 - accuracy: 0.1345\n",
            "Epoch 1894/10000\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 6.6160 - accuracy: 0.1675\n",
            "Epoch 1895/10000\n",
            " 9/32 [=======>......................] - ETA: 0s - loss: 8.3590 - accuracy: 0.3564"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-49-ebb8a5d4ac1a>\", line 1, in <module>\n",
            "    model = LSTMPoetryModel(ModelConfig)\n",
            "  File \"<ipython-input-48-e11c8b9aaec8>\", line 20, in __init__\n",
            "    self.train()\n",
            "  File \"<ipython-input-48-e11c8b9aaec8>\", line 222, in train\n",
            "    LambdaCallback(on_epoch_end=self.generate_sample_result)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1861, in fit_generator\n",
            "    initial_epoch=initial_epoch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\n",
            "    tmp_logs = self.train_function(iterator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 855, in _call\n",
            "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2943, in __call__\n",
            "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 560, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/genericpath.py\", line 19, in exists\n",
            "    os.stat(path)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '<ipython-input-49-ebb8a5d4ac1a>'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
            "    if os.path.exists(filename):\n",
            "  File \"/usr/lib/python3.6/genericpath.py\", line 19, in exists\n",
            "    os.stat(path)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "9JpAPMoMIAtV",
        "outputId": "2c8812ae-2aed-4d7d-e52f-2541dd431bbb"
      },
      "source": [
        "for i in range(3):\r\n",
        "    #藏头诗\r\n",
        "    sen = model.predict_hide('风起云涌')\r\n",
        "    print(sen)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2faa863715fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#藏头诗\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_hide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'风起云涌'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngfNFyAXIDVM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW5I4gzyVsTt"
      },
      "source": [
        ""
      ]
    }
  ]
}